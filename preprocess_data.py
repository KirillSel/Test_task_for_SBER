# -*- coding: utf-8 -*-
"""preprocess_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QQqNzsMKndhufKdsyMuGcHQotLUT2TKT
"""

import pandas as pd
import re
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from argparse import Namespace, ArgumentParser

from sklearn.metrics import classification_report, confusion_matrix, f1_score, make_scorer
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV

def arg_parser() -> Namespace:

    parser = ArgumentParser()

    parser.add_argument('--url_train_analysis',
                        type=str,
                        required=True,
                        help='Path to train data with anaysis')

    parser.add_argument('--url_train_info',
                        type=str,
                        required=True,
                        help='Path to train data with patient info')

    parser.add_argument('--url_test_analysis',
                        type=str,
                        required=True,
                        help='Path to test data with anaysis')

    parser.add_argument('--url_test_info',
                        type=str,
                        required=True,
                        help='Path to test data with patient info')

    parser.add_argument('--save_train_df_path',
                        type=str,
                        required=True,
                        help='Path where to save preprocessed train df')

    parser.add_argument('--save_test_df_path',
                        type=str,
                        required=True,
                        help='Path where to save preprocessed test df')


    args = parser.parse_args()

    return args


def main(args):
    test_analysis = pd.read_csv(args.url_test_analysis)
    test_info = pd.read_csv(args.url_test_info)
    train_analysis = pd.read_csv(args.url_train_analysis)
    train_info = pd.read_csv(args.url_train_info)

    # merge train_info и train_analysis по столбцу id
    train_df = pd.merge(train_info, train_analysis, on='id')
    # merge test_info и test_analysis по столбцу id
    test_df = pd.merge(test_info, test_analysis, on='id')

    train_df = train_df.set_index('id')
    test_df = test_df.set_index('id')

    print(train_df.info())
    print("\n")
    print(test_df.info())

    # в колонках weight есть пропуски
    print(train_df.isna().sum())
    print("\n")
    print(test_df.isna().sum())

    # заполняю пропуски средним по столбцу
    train_df['weight'].fillna(train_df['weight'].mean(), inplace=True)
    test_df['weight'].fillna(test_df['weight'].mean(), inplace=True)

    print(train_df['gender'].unique())
    print("\n")
    print(test_df['gender'].unique())

    # приводим к значениям m и f в столбце gender
    train_df['gender'] = train_df['gender'].replace({'male': 'm', 'female': 'f'})
    test_df['gender'] = test_df['gender'].replace({'male': 'm', 'female': 'f'})

    categorical_features = ['gender', 'cholesterol', 'gluc']

    # Кодируем One-Hot-Encoding категориальные признаки в train_df
    train_df = pd.get_dummies(train_df, columns = categorical_features, prefix = categorical_features)

    # Кодируем One-Hot-Encoding категориальные признаки в test_df
    test_df = pd.get_dummies(test_df, columns = categorical_features, prefix = categorical_features)

    # Разбиваем давление на 2 столбца systolic_pressure и diastolic_pressure
    train_df[['systolic_pressure', 'diastolic_pressure']] = train_df['pressure'].str.extract(r'(\d+)[/\\](\d+)')
    train_df['systolic_pressure'] = train_df['systolic_pressure'].astype(float)

    train_df['diastolic_pressure'] = train_df['diastolic_pressure'].astype(float)

    train_df = train_df.drop(columns=['pressure'])

    test_df[['systolic_pressure', 'diastolic_pressure']] = test_df['pressure'].str.extract(r'(\d+)[/\\](\d+)')

    test_df['systolic_pressure'] = test_df['systolic_pressure'].astype(float)
    test_df['diastolic_pressure'] = test_df['diastolic_pressure'].astype(float)

    test_df = test_df.drop(columns=['pressure'])

    test_df.isna().sum()

    test_df[test_df['systolic_pressure'].isna()]

    test_df['systolic_pressure'].fillna(test_df['systolic_pressure'].mean(), inplace=True)
    test_df['diastolic_pressure'].fillna(test_df['diastolic_pressure'].mean(), inplace=True)

    plt.hist(train_df['age'], bins=30, color='blue', edgecolor='black')
    plt.title('Распределение возраста')
    plt.xlabel('Возраст')
    plt.ylabel('Частота')
    plt.show()

    # столбец age содержит нереальные данные. Предположение, большие числа это дни. Переведем их в года, разделив на 365. Можно было бы вообще выкинуть этот столбец, но возраст должен коррелировать с наличием диабета.
    mask_train = train_df['age'] > 150
    mask_test = test_df['age'] > 150

    train_df.loc[mask_train, 'age'] /= 365
    test_df.loc[mask_test, 'age'] /= 365

    train_df['age'] = np.floor(train_df['age']).astype(int)
    test_df['age'] = np.floor(test_df['age']).astype(int)

    plt.hist(train_df['age'], bins=30, color='blue', edgecolor='black')
    plt.title('Распределение возраста')
    plt.xlabel('Возраст')
    plt.ylabel('Частота')
    plt.show()

    test_df['diabetes'].value_counts()

    sns.set(style="whitegrid")
    plt.figure(figsize=(8, 6))
    sns.countplot(x='diabetes', data=train_df, palette='Set2')

    plt.title('Распределение целевого признака "diabetes"')
    plt.xlabel('Значение')
    plt.ylabel('Частота')
    plt.show()

    train_df.to_csv(args.save_train_df_path, index=False)
    test_df.to_csv(args.save_test_df_path, index=False)


if __name__ == '__main__':
    main(arg_parser())
